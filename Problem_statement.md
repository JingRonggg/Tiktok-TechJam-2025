# Privacy Meets AI: Building a Safer Digital Future

## Problem Statment

- As AI technologies rapidly integrate into our daily lives, concerns about privacy and security have become more urgent than ever. With the rise of powerful generative AI models, large-scale data collection, and cloud-based deployment, users face increasing risks: sensitive data leakage, identity theft, etc.
- This hackathon invites participants to explore solutions in the following areas:
  - Enhancing the privacy of AI systems themselves (Privacy of AI); and/or
  - Using AI to defend user privacy and security (AI for Privacy).

## Background 

- In recent years, Generative AI (GenAI) has revolutionized countless industries. These large language models or large vision language models offer massive productivity boosts, unlocking creative potential and accelerating workflows like never before.
- As GenAI systems become more powerful and accessible, concerns about their misuse are rising sharply. From deepfakes to AI-based privacy attacks, malicious actors are already exploiting these tools to deceive and harm. At the same time, the usage of GenAI models themselves poses privacy risks: deploying LLMs on the cloud (MLaaS, machine learning as a service) requires the transmission of user prompts, which might contain sensitive information, posing potential privacy leakage

Over the next 72 hours, you'll explore how to:
- Make AI systems resilient against attacks and misuse.
- Or use AI to protect users' privacy

## Task Requirements

- To complete this project, you may need a laptop, mobile (Android or iOS) device, GPU (optional)
- Notes:
  1. The solution should not attempt to re-identify any individuals or personal information.
  2. If using personally identifiable information (PII), participants must delete all of it upon completion of TechJam.
  3. Must agree to open source licensing terms, as needed.
  4. Topic selection is not restricted to the directions outlined above.
    - Participants are encouraged to propose innovative ideas, provided they are relevant to the theme.
    - Participants are welcome to use open-source ML models and datasets for task-specific fine-tuning, in order to better tailor their solutions to AI privacy or AI-for-privacy topics outlined in this problem statement.
